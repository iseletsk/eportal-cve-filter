"""
Copyright 2023 Cloud Linux Software, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

import re
import csv
import logging

import json
import argparse

import requests
from requests.auth import HTTPBasicAuth
import xml.etree.ElementTree as ET


__author__ = "Cloud Linux Software, Inc."
__copyright__ = "Copyright (C) 2023 Cloud Linux Software, Inc."
__license__ = "Apache License, Version 2.0"
__version__ = "0.1"

class KpatchInfo:
    cache = {}
    cache_file = None

    def __init__(self, cache_file=None):
        self.cache_file = cache_file
        if self.cache_file:
            try:
                with open(cache_file, "rb") as f:
                    self.cache = json.loads(f.read().decode("utf-8"))
            except FileNotFoundError:
                pass  # Ignore inability to load cache file

    @staticmethod
    def _key(kernel_id: str, patch_level: str):
        return f"{kernel_id}/{patch_level}"

    def _get_cached(self, kernel_id: str, patch_level: str):
        result = self.cache.get(self._key(kernel_id, patch_level), None)
        if result:
            return set(result.split(","))
        return None

    def _set_cached(self, kernel_id: str, patch_level: str, kpatch_cve_set: set):
        self.cache[self._key(kernel_id, patch_level)] = ",".join(kpatch_cve_set)
        if self.cache_file:
            with open(self.cache_file, "wb") as f:
                f.write(json.dumps(self.cache).encode("utf-8"))

    def get(self, kernel_id: str, patch_level: str):
        cached = self._get_cached(kernel_id, patch_level)
        if cached:
            return cached
        url = f"{BASE_URL}/{kernel_id}/{patch_level}/kpatch.info"
        print("Retrieving kpatch.info from", url)
        # Download the file
        try:
            response = requests.get(url)
            response.raise_for_status()
        except requests.RequestException as e:
            raise Exception(f"Failed to download kpatch.info: {e}")

        kpatch_cve_set = set()
        # Parse the file to retrieve kpatch-cve entries
        for line in response.text.split("\n"):
            if line.startswith("kpatch-cve:"):
                kpatch_cve = line.split(":", 1)[1].strip().split(' ')[0]
                if kpatch_cve:
                    kpatch_cve_set.add(kpatch_cve)

        self._set_cached(kernel_id, patch_level, kpatch_cve_set)
        return kpatch_cve_set


def parse_eportal_report(parsed_json):
    if "result" not in parsed_json:
        raise Exception("Missing 'result' field in JSON")

    extracted_info_list = []

    for entry in parsed_json["result"]:
        if all(key in entry for key in ["ip", "hostname", "kernel_id", "patch_level"]):
            ip = entry["ip"]
            hostname = entry["hostname"]
            kernel_id = entry["kernel_id"]
            patch_level = entry["patch_level"]

            extracted_info = {
                "ip": ip,
                "hostname": hostname,
                "kernel_id": kernel_id,
                "patch_level": patch_level
            }

            extracted_info_list.append(extracted_info)

    return extracted_info_list


def load_patched_cves(eportal_report_json, ignore_ip=False, cache_file=None):
    extracted_info_list = parse_eportal_report(eportal_report_json)
    results = {}
    ip = _IP_NONE_VALUE
    kpatch_info = KpatchInfo(cache_file)
    for extracted_info in extracted_info_list:
        kernel_id = extracted_info["kernel_id"]
        patch_level = extracted_info["patch_level"]
        if not kernel_id or not patch_level or patch_level == -1:
            continue  # skip if no kernel_id or patch_level is present
        hostname = extracted_info["hostname"]
        if not ignore_ip:
            ip = extracted_info["ip"]
        try:
            kpatch_cve_set = kpatch_info.get(kernel_id, patch_level)
            results[f"{hostname}|{ip}"] = kpatch_cve_set
        except Exception as e:
            print(f"Error retrieving entries for {hostname}|{ip} {kernel_id}-{patch_level}:", e)
    return results

class AlasInfo:

    _cache = {}
    sources = [
        "https://alas.aws.amazon.com/alas.rss",
        "https://alas.aws.amazon.com/AL2/alas.rss",
        "https://alas.aws.amazon.com/AL2023/alas.rss",
    ]
    alas_pattern = r'ALAS(?:-\d{4})?-\d+'

    def __init__(self, cache_file=None):
        self.cache_file = cache_file
        if not self.cache_file:
            return
        try:
            with open(cache_file, "rb") as f:
                data = f.read().decode("utf-8")
                if data:
                    self._cache = json.loads(data)
        except FileNotFoundError:
            pass

    def get(self, alas):
        if not self._cache:
            self.populate()
        return self._cache.get(alas, [])

    def populate(self):
        for source in self.sources:
            response = requests.get(source)
            response.raise_for_status()
            root = ET.fromstring(response.content)
            for item in root.findall('.//item'):  # Adjust the path based on the XML structure
                title = item.find('title')
                description = item.find('description')
                if title is None or description is None:
                    continue
                match = re.search(self.alas_pattern, title.text)
                if not match:
                    continue
                alas_id = match.group(0)
                cve_list = [cve.strip() for cve in description.text.split(",")]
                if alas_id not in self._cache:
                    self._cache[alas_id] = []
                self._cache[alas_id].extend(cve_list)
        # Save the cache
        if self.cache_file:
            print(self._cache)
            with open(self.cache_file, "wb") as f:
                f.write(json.dumps(self._cache).encode("utf-8"))





def process_csv_file(csvreader, csvwriter, eportal_servers_json, hostname_column, ip_column, cve_column,
                     mutiple_cves_separator=None, ignore_ip=False, cache_file=None):
    ip = _IP_NONE_VALUE
    cve_data = load_patched_cves(eportal_servers_json, ignore_ip, cache_file)
    alas_map = AlasInfo(cache_file='.alas'+cache_file)
    for row in csvreader:
        try:
            hostname = row[hostname_column]
            if not ignore_ip:
                ip = row[ip_column]
            cve_field = row[cve_column]
        except Exception as e:
            print(f"Error parsing row {row}: {e}")
            continue

        patched_cves = cve_data.get(f"{hostname}|{ip}", set())
        if mutiple_cves_separator:
            _found_cves = list(cve_field.split(mutiple_cves_separator))
        else:
            _found_cves = [cve_field, ]

        # If the CVE is an ALAS, we need to convert it to a CVE
        found_cves = set()
        for cve in _found_cves:
            if cve.startswith("ALAS-"):
                mapped_cve = alas_map.get(cve)
                assert mapped_cve, f"ALAS {cve} not found"
                cve = mapped_cve
            else:
                cve = {cve}
            found_cves.update(cve)

        unpatched_cves = []
        for cve in found_cves:
            if cve not in patched_cves:
                unpatched_cves.append(cve)

        if len(unpatched_cves) > 0:
            if mutiple_cves_separator:
                row[cve_column] = mutiple_cves_separator.join(unpatched_cves)
            csvwriter.writerow(row)
        # otherwise we patched all CVEs, skip the row
            
def get_servers_from_eportal(url, username, password):
    # Construct the complete API endpoint URL
    api_endpoint = f"{url}/admin/api/servers"

    try:
        # Make a GET request to the ePortal API
        response = requests.get(api_endpoint, auth=HTTPBasicAuth(username, password))

        # Check if the request was successful
        if response.status_code == 200:
            # Parse the JSON response
            return response.json()
        else:
            return {"error": f"Received {response.status_code} status code from the server"}
    except Exception as e:
        return {"error": str(e)}


def process_csv_wrapper(in_file, out_file, eportal_servers_json, hostname_column, ip_column, cve_column,
                        mutiple_cves_separator=None, ignore_ip=False, cache_file=None):
    with open(out_file, "w") as out_f:
        csvwriter = csv.writer(out_f)
        with open(in_file) as f:
            csvreader = csv.reader(f)
            return process_csv_file(csvreader, csvwriter, eportal_servers_json, hostname_column, ip_column, cve_column,
                                    mutiple_cves_separator, ignore_ip, cache_file)


BASE_URL = "https://patches.kernelcare.com"
KPATCH_INFO_CACHE_FILE = ".kpatch_info_cache.json"
_IP_NONE_VALUE = "NA"

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Filter out patched CVEs from CSV files using ePortal data')

    parser.add_argument('--columns', type=str, required=True,
                        help='Columns in CSV file: hostname,ip,cve. Start with 1. Use 0 for ip if column not present')
    parser.add_argument('--multi-cve-separator', type=str, default=None,
                        help='Separator if CVE column can contain multiple CVEs')
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--eportal-url', type=str,
                       help='URL to ePortal, set EPORTAL_LOGIN and EPORTAL_PASSWORD env variables')
    group.add_argument('--eportal-report-file', type=str,
                       help='File containing output of servers endpoint '
                            'https://docs.tuxcare.com/eportal-api/#list-servers')
    parser.add_argument('--csv-file-in', type=str, required=True, help='Input CSV filename')
    parser.add_argument('--csv-file-out', type=str, required=False,
                        help='Output CSV filename, if missing CSV is printed to stdout')

    args = parser.parse_args()

    columns = args.columns.split(',')
    hostname_column = int(columns[0]) - 1
    ip_column = int(columns[1]) - 1
    cve_column = int(columns[2]) - 1

    multi_cve_separator = args.multi_cve_separator

    eportal_url = args.eportal_url
    if eportal_url:
        import os

        eportal_login = os.environ.get("EPORTAL_LOGIN")
        eportal_password = os.environ.get("EPORTAL_PASSWORD")
        parsed_json = get_servers_from_eportal(eportal_url, eportal_login, eportal_password)
    else:
        with open(args.eportal_report_file, 'r') as f:
            json_string = f.read()
            try:
                parsed_json = json.loads(json_string)
            except json.JSONDecodeError as e:
                raise Exception(f"Invalid JSON: {e}")

    csv_file_in = args.csv_file_in
    try:
        csv_file_in_fd = open(csv_file_in, "r")
    except Exception as e:
        logging.error(f"Failed to open input CSV file {csv_file_in}: {e}")
        exit(1)
    csv_file_out = args.csv_file_out
    if csv_file_out:
        csv_file_out_fd = open(csv_file_out, "w")
    else:
        import sys

        csv_file_out_fd = sys.stdout

    csvreader = csv.reader(csv_file_in_fd)
    csvwriter = csv.writer(csv_file_out_fd)
    process_csv_file(csvreader, csvwriter, eportal_servers_json=parsed_json,
                     hostname_column=hostname_column, ip_column=ip_column, cve_column=cve_column,
                     mutiple_cves_separator=multi_cve_separator,
                     ignore_ip=ip_column < 0,
                     cache_file=KPATCH_INFO_CACHE_FILE)


# with open("../new_server_file.json") as json_file:
#     servers_json = json.loads(json_file.read())
#     process_csv_wrapper(in_file="testreport.csv", out_file="testreport_out.csv", eportal_servers_json=servers_json,
#                      hostname_column=0, ip_column=1, cve_column=3, mutiple_cves_separator=",",
#                      ignore_ip=True, cache_file=KPATCH_INFO_CACHE_FILE)
